{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOob1GhPSsnVDJ73f9DVTrI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matusoff/ML_models/blob/main/pySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario for the project: Suppose a Dog Food company asked to predict why their manufactured food is being spoiled rapidly compared to their shelf’s life. We will solve this particular problem statement using PySpark’s MLIB.\n",
        "\n",
        "Our main task is to predict that 1 chemical/preservative has the strongest effect among those 4 ingredients, and to achieve this, we are not gonna follow the train test split methodology but instead feature importance method because, in the end, that only will let us know which of those ingredients is most responsible for spoiling the dog food before its shelf life.\n",
        "\n",
        "The dataset holds 4 feature columns labeled A, B, C, and D, and the Target column labeled “Spoiled.”\n",
        "\n",
        "Dataset: https://drive.google.com/file/d/1TD9-03UwXRLG2i24zThJwh6qtgPkgUzK/view?usp=sharing"
      ],
      "metadata": {
        "id": "1l1jEpPTm-UG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8B6L3Rz8nvd",
        "outputId": "b069568a-5044-499e-c6fc-32c2ce522c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=299292df19efad6029b0a205f4a0c3703a62787073d7b4fbe7c628b6b4354244\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "Sc2IaHFO8vOS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "xpWfcXM987LY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('Practise').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Z8uJCNG_9FQX",
        "outputId": "6c3de415-89f1-406e-dc57-6e3dba3b7253"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a7a1ff99210>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a3751e878aee:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practise</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df =spark.read.csv('/content/sample_data/dog_food.csv')\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMSUSXDh9e0u",
        "outputId": "430ec028-08d8-4f07-db45-540304601aa5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+---+-------+\n",
            "|_c0|_c1| _c2|_c3|    _c4|\n",
            "+---+---+----+---+-------+\n",
            "|  A|  B|   C|  D|Spoiled|\n",
            "|  4|  2|12.0|  3|    1.0|\n",
            "|  5|  6|12.0|  7|    1.0|\n",
            "|  6|  2|13.0|  6|    1.0|\n",
            "|  4|  2|12.0|  1|    1.0|\n",
            "|  4|  2|12.0|  3|    1.0|\n",
            "| 10|  3|13.0|  9|    1.0|\n",
            "|  8|  5|14.0|  5|    1.0|\n",
            "|  5|  8|12.0|  8|    1.0|\n",
            "|  6|  5|12.0|  9|    1.0|\n",
            "|  3|  3|12.0|  1|    1.0|\n",
            "|  9|  8|11.0|  3|    1.0|\n",
            "|  1| 10|12.0|  3|    1.0|\n",
            "|  1|  5|13.0| 10|    1.0|\n",
            "|  2| 10|12.0|  6|    1.0|\n",
            "|  1| 10|11.0|  4|    1.0|\n",
            "|  5|  3|12.0|  2|    1.0|\n",
            "|  4|  9|11.0|  8|    1.0|\n",
            "|  5|  1|11.0|  1|    1.0|\n",
            "|  4|  9|12.0| 10|    1.0|\n",
            "+---+---+----+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.option('header', 'true').csv('/content/sample_data/dog_food.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMmcTKPGAvK0",
        "outputId": "0dc39bbf-4a43-449d-8b43-372c50c2f736"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[A: string, B: string, C: string, D: string, Spoiled: string]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.option('header', 'true').csv('/content/sample_data/dog_food.csv', inferSchema = True )"
      ],
      "metadata": {
        "id": "aRhimp4RCBlM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LClTkp-ZG0w9",
        "outputId": "53847928-9138-4608-f04a-948f75f39cc4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- A: integer (nullable = true)\n",
            " |-- B: integer (nullable = true)\n",
            " |-- C: double (nullable = true)\n",
            " |-- D: integer (nullable = true)\n",
            " |-- Spoiled: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m_5Y5xGBSVG",
        "outputId": "aeab8ad5-1f12-4b2b-98ef-3f78e36e09fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hoRNLhwBWTz",
        "outputId": "da975ebf-6bab-4fd9-f40c-9b7770dd515a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(A=4, B=2, C=12.0, D=3, Spoiled=1.0),\n",
              " Row(A=5, B=6, C=12.0, D=7, Spoiled=1.0),\n",
              " Row(A=6, B=2, C=13.0, D=6, Spoiled=1.0),\n",
              " Row(A=4, B=2, C=12.0, D=1, Spoiled=1.0),\n",
              " Row(A=4, B=2, C=12.0, D=3, Spoiled=1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sM1XyxzCNMw",
        "outputId": "33615ca0-54c8-49f7-f3a4-e1b28af112cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
            "|summary|                 A|                 B|                 C|                 D|            Spoiled|\n",
            "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
            "|  count|               490|               490|               490|               490|                490|\n",
            "|   mean|  5.53469387755102| 5.504081632653061| 9.126530612244897| 5.579591836734694| 0.2857142857142857|\n",
            "| stddev|2.9515204234399057|2.8537966089662063|2.0555451971054275|2.8548369309982857|0.45221563164613465|\n",
            "|    min|                 1|                 1|               5.0|                 1|                0.0|\n",
            "|    max|                10|                10|              14.0|                10|                1.0|\n",
            "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vector Assembler and Vectors in PySpark"
      ],
      "metadata": {
        "id": "dNwejwn4lS7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can place all the features together in one separate column, while keeping the target column in another one."
      ],
      "metadata": {
        "id": "akKwKYsQlh-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "metadata": {
        "id": "DowF-pcLCXMa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler_df = VectorAssembler(inputCols=['A', 'B', 'C', 'D'],outputCol=\"features\")\n",
        "output = assembler_df.transform(df)\n",
        "output.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMhDaWoEl3OK",
        "outputId": "15905e85-45b5-481f-c2c8-0fa11bef7251"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+---+-------+-------------------+\n",
            "|  A|  B|   C|  D|Spoiled|           features|\n",
            "+---+---+----+---+-------+-------------------+\n",
            "|  4|  2|12.0|  3|    1.0| [4.0,2.0,12.0,3.0]|\n",
            "|  5|  6|12.0|  7|    1.0| [5.0,6.0,12.0,7.0]|\n",
            "|  6|  2|13.0|  6|    1.0| [6.0,2.0,13.0,6.0]|\n",
            "|  4|  2|12.0|  1|    1.0| [4.0,2.0,12.0,1.0]|\n",
            "|  4|  2|12.0|  3|    1.0| [4.0,2.0,12.0,3.0]|\n",
            "| 10|  3|13.0|  9|    1.0|[10.0,3.0,13.0,9.0]|\n",
            "|  8|  5|14.0|  5|    1.0| [8.0,5.0,14.0,5.0]|\n",
            "|  5|  8|12.0|  8|    1.0| [5.0,8.0,12.0,8.0]|\n",
            "|  6|  5|12.0|  9|    1.0| [6.0,5.0,12.0,9.0]|\n",
            "|  3|  3|12.0|  1|    1.0| [3.0,3.0,12.0,1.0]|\n",
            "|  9|  8|11.0|  3|    1.0| [9.0,8.0,11.0,3.0]|\n",
            "|  1| 10|12.0|  3|    1.0|[1.0,10.0,12.0,3.0]|\n",
            "|  1|  5|13.0| 10|    1.0|[1.0,5.0,13.0,10.0]|\n",
            "|  2| 10|12.0|  6|    1.0|[2.0,10.0,12.0,6.0]|\n",
            "|  1| 10|11.0|  4|    1.0|[1.0,10.0,11.0,4.0]|\n",
            "|  5|  3|12.0|  2|    1.0| [5.0,3.0,12.0,2.0]|\n",
            "|  4|  9|11.0|  8|    1.0| [4.0,9.0,11.0,8.0]|\n",
            "|  5|  1|11.0|  1|    1.0| [5.0,1.0,11.0,1.0]|\n",
            "|  4|  9|12.0| 10|    1.0|[4.0,9.0,12.0,10.0]|\n",
            "|  5|  8|10.0|  9|    1.0| [5.0,8.0,10.0,9.0]|\n",
            "+---+---+----+---+-------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model building using PySpark"
      ],
      "metadata": {
        "id": "qiaJhatSmInY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier,DecisionTreeClassifier\n",
        "\n",
        "rfc = DecisionTreeClassifier(labelCol='Spoiled',featuresCol='features')"
      ],
      "metadata": {
        "id": "g23Uv4gAmJx5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = output.select('features','Spoiled')\n",
        "final_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VMMVPfTmamo",
        "outputId": "0cf60636-3456-4669-b0b7-5c7ac87bb1a5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------+\n",
            "|           features|Spoiled|\n",
            "+-------------------+-------+\n",
            "| [4.0,2.0,12.0,3.0]|    1.0|\n",
            "| [5.0,6.0,12.0,7.0]|    1.0|\n",
            "| [6.0,2.0,13.0,6.0]|    1.0|\n",
            "| [4.0,2.0,12.0,1.0]|    1.0|\n",
            "| [4.0,2.0,12.0,3.0]|    1.0|\n",
            "|[10.0,3.0,13.0,9.0]|    1.0|\n",
            "| [8.0,5.0,14.0,5.0]|    1.0|\n",
            "| [5.0,8.0,12.0,8.0]|    1.0|\n",
            "| [6.0,5.0,12.0,9.0]|    1.0|\n",
            "| [3.0,3.0,12.0,1.0]|    1.0|\n",
            "| [9.0,8.0,11.0,3.0]|    1.0|\n",
            "|[1.0,10.0,12.0,3.0]|    1.0|\n",
            "|[1.0,5.0,13.0,10.0]|    1.0|\n",
            "|[2.0,10.0,12.0,6.0]|    1.0|\n",
            "|[1.0,10.0,11.0,4.0]|    1.0|\n",
            "| [5.0,3.0,12.0,2.0]|    1.0|\n",
            "| [4.0,9.0,11.0,8.0]|    1.0|\n",
            "| [5.0,1.0,11.0,1.0]|    1.0|\n",
            "|[4.0,9.0,12.0,10.0]|    1.0|\n",
            "| [5.0,8.0,10.0,9.0]|    1.0|\n",
            "+-------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc_model = rfc.fit(final_data)"
      ],
      "metadata": {
        "id": "hNZATmU9mhsH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc_model.featureImportances"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ6PL7M5mn3E",
        "outputId": "c5a44eb2-642e-49d0-b2d9-82aca5ddd8e2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseVector(4, {1: 0.0019, 2: 0.9832, 3: 0.0149})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VpZLFA6Ssb7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Have a close look at the output where 3 indexes are there and 2nd index has the highest value (0.9832) i.e.\n",
        "\n",
        "Chemical C is the most important feature that stimulates Chemical C and is the main cause of the early spoilage of dog food."
      ],
      "metadata": {
        "id": "5f5tA-l6suke"
      }
    }
  ]
}